{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zi6I6Eu16GqG"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install lightgbm --quiet\n",
        "!apt-get install -y -qq libboost-dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import lightgbm as lgb\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# === Load raw CSVs ===\n",
        "train_set_path = '/content/train_set.csv'\n",
        "test_set_path = '/content/test_set.csv'\n",
        "train_set = pd.read_csv(train_set_path)\n",
        "test_set = pd.read_csv(test_set_path)\n",
        "record_ids = test_set['RecordId']\n",
        "\n",
        "# === Define preprocessing function ===\n",
        "def preprocess(df, is_train=True):\n",
        "    df.drop(columns=['RecordId', 'X71', 'X76'], inplace=True)\n",
        "    if is_train:\n",
        "        X = df.drop(columns=['Y'])\n",
        "        Y = df['Y']\n",
        "        return X, Y\n",
        "    else:\n",
        "        return df\n",
        "\n",
        "# === Parallel preprocessing ===\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future_train = executor.submit(preprocess, train_set, True)\n",
        "    future_test = executor.submit(preprocess, test_set, False)\n",
        "    X, Y = future_train.result()\n",
        "    test_X = future_test.result()\n",
        "\n",
        "# === Imputation and Scaling (done once, sequentially) ===\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Train\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Test\n",
        "test_imputed = imputer.transform(test_X)\n",
        "test_scaled = scaler.transform(test_imputed)\n",
        "\n",
        "# Split into train/validation\n",
        "X_train, X_validate, Y_train, Y_validate = train_test_split(X_scaled, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "# === Train LightGBM with GPU and multithreading ===\n",
        "model = lgb.LGBMClassifier(\n",
        "    boosting_type='gbdt',\n",
        "    device_type='gpu',\n",
        "    max_depth=10,\n",
        "    n_estimators=290,\n",
        "    learning_rate=0.025,\n",
        "    colsample_bytree=0.19,\n",
        "    min_child_weight=2,\n",
        "    reg_alpha=0.19,\n",
        "    reg_lambda=0.19,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    num_threads=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# === Evaluate ===\n",
        "md_predictions_probs = model.predict_proba(X_validate)[:, 1]\n",
        "md_roc = roc_auc_score(Y_validate, md_predictions_probs)\n",
        "print(\"Validation ROC AUC:\", md_roc)\n",
        "\n",
        "# === Predict on test set ===\n",
        "test_predictions_probs = model.predict_proba(test_scaled)[:, 1]\n",
        "\n",
        "# === Save submission ===\n",
        "submission = pd.DataFrame({\n",
        "    'RecordId': record_ids,\n",
        "    'Y': test_predictions_probs\n",
        "})\n",
        "submission.to_csv('submission_pipeline_gpu_multithreaded.csv', index=False)\n",
        "print(\"Submission file created: submission_pipeline_gpu_multithreaded.csv\")\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "print(f\"Total execution time: {end_time - start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23lfW0kU6LA4",
        "outputId": "ce3d3295-9aff-4133-8818-2a5e9cbb86d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 466, number of negative: 171819\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 17366\n",
            "[LightGBM] [Info] Number of data points in the train set: 172285, number of used features: 75\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 62 dense feature groups (10.52 MB) transferred to GPU in 0.012564 secs. 1 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002705 -> initscore=-5.910011\n",
            "[LightGBM] [Info] Start training from score -5.910011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC AUC: 0.969476021468568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created: submission_pipeline_gpu_multithreaded.csv\n",
            "Total execution time: 16.77 seconds\n"
          ]
        }
      ]
    }
  ]
}